# MNIST手寫數字辨識資料集_深度學習模型

## 專案介紹

1. 本專案目的為藉由MNIST手寫數字辨識資料集來實作深度學習模型，並探索其中差異。
2. 使用MLP嘗試將模型加寬、加深，以提高準確率，並且加入Drop層，以避免Overfitting問題。
3. MLP有其極限，可使用CNN來提高準確率

## 資料來源

1. MNIST手寫數字辨識資料集，是由Yann LeCun大神所蒐集，這位大神同時也是Convolutional Neural Networks(卷積神經網絡)的創始人，因此享有“CNN 之父"的美譽
2. 由於MNIST的資料大小適中，而且皆為單色影像(黑字白底)，十分適合做為初學者第一個建立模型、訓練、與預測的資料集
3. MNIST資料集是由60,000筆訓練資料、10,000筆測試資料所組成。
4. MNIST資料集裡的每一筆資料皆由images(數字的影像)與labels(該圖片的真 實數字，其實就是答案)所組成

## 專案步驟：

- 了解資料
- 資料前處理
- 模型評估
- 結論

## 了解資料

1. 訓練資料：(60,000, 28, 28)
2. 測試資料：(10,000, 28, 28)

## 資料前處理

1. 二維轉換成一維資料：(60,000, 784)
2. 標準化
3. 轉換成數值資料：利用np_utils.to_categorical()方法

## 模型評估
|  模型結構  | 準確率 |
| ---------|--------| 
|    MLP   | 98.22% |
|    CNN   | 98.90% |
|    RNN   | 97.40% |
|   LSTM   | 98.26% |

## 結論
1. MLP原256個神經元增加至1000個，發現訓練的準確率比驗證還要高，此時可以增加DropOut功能，使解決Overfitting問題
2. 辨識數字影像使用MLP、CNN、RNN、LSTM這四種模型皆能達到不錯效果
3. 此外，RNN及LSTM可以解決時間序列、順序性的問題，例如：自然語言處理（必須考慮前後文字來判斷目前這句話的意義）
4. 時間遞迴模型：RNN可以取得短期記憶、LSTM屬於長短期記憶模型，可以解決RNN的long-term dependencies問題


